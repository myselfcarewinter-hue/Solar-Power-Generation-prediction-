# -*- coding: utf-8 -*-
"""Solar power generation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sA82jjJo01WKdKp297B-l1N-Ccw-6OD8
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
import os

os.makedirs('results/spg', exist_ok=True)
os.makedirs('data/spg_outputs', exist_ok=True)

df = pd.read_csv('spg.csv')
target = 'generated_power_kw'
X = df.drop(columns=[target])
y = df[target]
feature_names = X.columns.tolist()

print(f"Target variable: {target}")
print(f"Total features: {len(feature_names)}")
print("\nData Info:")
df.info()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = StandardScaler()

X_train_scaled = scaler.fit_transform(X_train)

X_test_scaled = scaler.transform(X_test)

print(f"Training features shape: {X_train_scaled.shape}")
print(f"Testing features shape: {X_test_scaled.shape}")

sns.set_style("whitegrid")

plt.figure(figsize=(10, 6))
sns.histplot(y, kde=True, bins=50)
plt.title('Distribution of Generated Power (kW) [spg.csv]')
plt.xlabel('Generated Power (kW)')
plt.ylabel('Frequency')

plt.savefig('results/spg/spg_target_distribution.png')
plt.show()

correlation_matrix = df.corr()

plt.figure(figsize=(18, 14))
sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', annot_kws={"size": 8})
plt.title('SPG Correlation Heatmap')
plt.xticks(rotation=45, ha='right')
plt.yticks(rotation=0)
plt.tight_layout()

plt.savefig('results/spg/spg_correlation_heatmap.png')
plt.show()

model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)

print("Training the power generation model...")
model.fit(X_train_scaled, y_train)
print("Model training complete!")

y_pred = model.predict(X_test_scaled)

r2 = r2_score(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))

print("\n--- Model Evaluation Results ---")
print(f"R-squared (R²): {r2:.4f}")
print(f"Root Mean Squared Error (RMSE): {rmse:.4f} kW")

predictions_df = pd.DataFrame({'Actual_Power': y_test, 'Predicted_Power': y_pred})

predictions_df.to_csv('data/spg_outputs/spg_model_predictions.csv', index=False)

print("Saved model predictions to 'data/spg_outputs/spg_model_predictions.csv'")

importances = model.feature_importances_

feature_importance_df = pd.DataFrame({
      'Feature': feature_names,
          'Importance': importances
          }).sort_values(by='Importance', ascending=False)

feature_importance_df.to_csv('data/spg_outputs/spg_feature_importance.csv', index=False)

print("--- Top 10 Most Important Features ---")
print(feature_importance_df.head(10))

!git config --global user.email "myselfcarewinter@gmail.com"
!git config --global user.name "myselfcarewinter-hue"

plt.figure(figsize=(12, 8))
sns.barplot(data=feature_importance_df.head(10), x='Importance', y='Feature')
plt.title('Top 10 Most Important Features (SPG)')

plt.savefig('results/spg/spg_feature_importance.png')
plt.show()

from sklearn.ensemble import GradientBoostingRegressor

gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)

print("Training the Gradient Boosting model...")
gb_model.fit(X_train_scaled, y_train)
print("Model training complete!")

y_pred_gb = gb_model.predict(X_test_scaled)

r2_gb = r2_score(y_test, y_pred_gb)
rmse_gb = np.sqrt(mean_squared_error(y_test, y_pred_gb))

print("\n--- Model Comparison ---")
print(f"Random Forest (Original):")
print(f"  R-squared (R²): {r2:.4f}")
print(f"  RMSE: {rmse:.4f} kW")
print(f"\nGradient Boosting (New):")
print(f"  R-squared (R²): {r2_gb:.4f}")
print(f"  RMSE: {rmse_gb:.4f} kW")

from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [100, 200, 300],
    'learning_rate': [0.01, 0.1, 0.2],
      'max_depth': [3, 5, 7]
            }

grid_search = GridSearchCV(
          estimator=GradientBoostingRegressor(random_state=42),
          param_grid=param_grid,
          cv=5,
          scoring='r2',
          n_jobs=-1,
          verbose=1
)
print("--- Starting Hyperparameter Tuning (this may take a few minutes)... ---")
grid_search.fit(X_train_scaled, y_train)
print("--- Tuning Complete! ---")
print("\nBest parameters found:")
print(grid_search.best_params_)
print(f"\nBest cross-validation R-squared (R²): {grid_search.best_score_:.4f}")

print("--- Evaluating the Tuned Gradient Boosting Model ---")

best_gb_model = grid_search.best_estimator_

y_pred_best_gb = best_gb_model.predict(X_test_scaled)

r2_best_gb = r2_score(y_test, y_pred_best_gb)
rmse_best_gb = np.sqrt(mean_squared_error(y_test, y_pred_best_gb))

print("\n--- Final Model Comparison ---")

print(f"Random Forest (Base):")
print(f"  R-squared: {r2:.4f}, RMSE: {rmse:.4f} kW")

print(f"\nGradient Boosting (Base):")
print(f"  R-squared: {r2_gb:.4f}, RMSE: {rmse_gb:.4f} kW")

print(f"\nGradient Boosting (TUNED):")
print(f"  R-squared: {r2_best_gb:.4f}, RMSE: {rmse_best_gb:.4f} kW")



print("--- Plotting Top Feature Relationships ---")
sns.set_style("darkgrid")

plt.figure(figsize=(18, 6))

plt.subplot(1, 3, 1)
sns.scatterplot(data=df, x='shortwave_radiation_backwards_sfc', y='generated_power_kw', alpha=0.5)
plt.title('Power vs. Shortwave Radiation')

plt.subplot(1, 3, 2)
sns.scatterplot(data=df, x='angle_of_incidence', y='generated_power_kw', alpha=0.5)
plt.title('Power vs. Angle of Incidence')

plt.subplot(1, 3, 3)
sns.scatterplot(data=df, x='zenith', y='generated_power_kw', alpha=0.5)
plt.title('Power vs. Zenith Angle')

plt.tight_layout()
plt.savefig('results/spg/top_feature_eda_plots.png')
plt.show()

import ipywidgets as widgets
from ipywidgets import interact, FloatSlider

print("--- Building Interactive Dashboard ---")

model_to_use = best_gb_model
# model_to_use = xgb_model  # <-- Uncomment this line if XGBoost was better

feature_averages = X.mean()

def predict_power(shortwave_radiation, angle_of_incidence, zenith):

        input_data = feature_averages.copy()
        input_data['shortwave_radiation_backwards_sfc'] = shortwave_radiation
        input_data['angle_of_incidence'] = angle_of_incidence
        input_data['zenith'] = zenith
        input_df = pd.DataFrame([input_data])
        input_scaled = scaler.transform(input_df)
        prediction = model_to_use.predict(input_scaled)
        print(f"Predicted Power Output: {prediction[0]:.2f} kW")
        interact(predict_power,shortwave_radiation=FloatSlider(min=df['shortwave_radiation_backwards_sfc'].min(), max=df['shortwave_radiation_backwards_sfc'].max(), value=df['shortwave_radiation_backwards_sfc'].mean(), step=10),
        angle_of_incidence=FloatSlider(min=df['angle_of_incidence'].min(), max=df['angle_of_incidence'].max(), value=df['angle_of_incidence'].mean(), step=1),
        zenith=FloatSlider(min=df['zenith'].min(), max=df['zenith'].max(), value=df['zenith'].mean(), step=1));

rad = float(input("enter the shortwave radiation: "))
aoi = float(input("enter the angle of incidence: "))
zen = float(input("enter the zenith angle:"))
predict_power(rad,aoi,zen)

!git init
!git add .
!git commit -m "Initial project commit: Added spg data, scripts, and results"

username = "myselfcarewinter-hue"
pat = "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"
repo_name = "Solar-Power-Generation-prediction-"

print("--- Initializing new Git repository ---")
!git init
print("\n--- Adding all files ---")
!git add .
print("\n--- Committing all files ---")
!git commit -m "Full project upload: data, results, and notebook"

print("\n--- Connecting to GitHub ---")

!git remote remove origin
!git remote add origin https://{username}:{pat}@github.com/{username}/{repo_name}.git
!git branch -M main

print("\n--- Pushing files to GitHub... ---")
!git push -u origin main

print("\n--- All Done! Refresh your GitHub page. ---")